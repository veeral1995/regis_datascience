{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce Assignment\n",
    "## MapReduce is the 'Hello World' problem of Apache Spark\n",
    "\n",
    "### Download The Complete Works of Shakespeare as a Plain Text UTF-8 from herehttps://www.gutenberg.org/ebooks/100 and download another Plain Text UTF-8 .txt file of a book of your choosing here: http://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\") # These are stop words that we will be using later.\n",
    "from nltk.corpus import stopwords\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import  SparkContext\n",
    "sc = SparkContext( 'local', 'pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribute the data - Create a RDD\n",
    "# Enter the file path to the Complete Works of Shakespeare.\n",
    "text = sc.textFile(\"/home/msds600/mapreduce/shakespeare.txt\") # Load Complete Works of Shakespeare as a Spark Content Resilient Distributed Dataset (RDD) of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at some Spark RDD comands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text # the RDD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.count() # Number of items in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.first() # First item in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.take(20) # First 20 items in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text.collect() # Collect everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a funtion to remove puncuation from the text\n",
    "def removePunctuation(text): # Create a function\n",
    "    text = text.lower().strip() # Change all letters to lowercase and remove leading and trailing white spaces\n",
    "    text = re.sub(r'\\W+', ' ', text) # Removes all numbers and charaters.  Leaves only letters.\n",
    "    return text # Return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Reduce\n",
    "cleantext = text.map(removePunctuation) # Remove puncuation\n",
    "\n",
    "wordcounts = (cleantext.flatMap(lambda x: x.split(' ')) # Split all the words           \n",
    "                  .map(lambda x: (x, 1))# Assign 1 to each word              \n",
    "                  .reduceByKey(lambda x,y : x + y))# # Count each word and reduce\n",
    "\n",
    "wordcounts.take(10) # Take the first 10 items      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcounts.takeOrdered(10, key=lambda x: -x[1]) # Sort the words by their count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above cell there are a lot of 'stop words', we may want to remove the stop words/\n",
    "stop = stopwords.words('english') # load english stopwords.\n",
    "stop.append('') # add the white space to the stop words.\n",
    "stop # Show the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = (cleantext.flatMap(lambda x: x.split(' '))) # flatten the words\n",
    "\n",
    "wordsstopped = [j for j in words.collect() if j not in stop] # Remove stop words\n",
    "\n",
    "wordsstopped_rdd = sc.parallelize(wordsstopped) # Convert back to RDD\n",
    "\n",
    "wordcounts = (wordsstopped_rdd.map(lambda x: (x, 1))# Assign 1 to each word                   \n",
    "                .reduceByKey(lambda x,y : x + y)) # Count each word and reduce\n",
    "\n",
    "wordcounts.take(10) # Take the first 10 items                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcounts.takeOrdered(25, key=lambda x: -x[1]) # Sort the words by their count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wordcounts.collect()) # Convert to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for specific words in the text.\n",
    "df[df[0].isin(['laugh'])] # Search for words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn\n",
    "## Download another Plain Text UTF-8 .txt book of your choosing from here: https://www.gutenberg.org/browse/scores/top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and the text as an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 50 items in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords from the text and perform a map reduce of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the most common 50 words in the text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a word of your choosing in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit this jupyter notebook with the outputs displayed to the Week 7 assignments folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
